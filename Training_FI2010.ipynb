{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf # tensorflow v2.2.1\n",
    "# from tensorflow.compat.v1.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "# limit gpu usage for keras\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model Architect\n",
    "def create_deeplob(T, NF, number_of_lstm):\n",
    "    input_lmd = Input(shape=(T, NF, 1))\n",
    "    \n",
    "    # build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "\n",
    "    # use the MC dropout here\n",
    "    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "\n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = LSTM(number_of_lstm)(conv_reshape)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "deeplob = create_deeplob(100, 40, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load postgreSQL data\n",
    "\n",
    "# Prepare data\n",
    "def get_SQLtrain1(index, conn):\n",
    "\n",
    "    queryLob = f'''SELECT * FROM \"NoAuction_DecPre\" \n",
    "                  WHERE \"RandID\" = {index}\n",
    "                  AND istrainingdata = 1\n",
    "                  limit 200;'''  # limit for testing only\n",
    "    ResLob = pd.read_sql(queryLob, conn)\n",
    "    sqlTrainLob = ResLob.loc[:, 'pa1':'vb10']\n",
    "    \n",
    "    queryLabel = f'''SELECT * FROM \"NoAuction_DecPre_Label\" \n",
    "                    WHERE \"RandID\" = {index}\n",
    "                    AND istrainingdata = 1\n",
    "                    limit 200;'''\n",
    "    ResLabel = pd.read_sql(queryLabel, conn)\n",
    "    sqlTrainLabel = ResLabel.loc[:, 'direction']\n",
    "    sqlTrainLabel = sqlTrainLabel*(-1) + 2 - 1\n",
    "    \n",
    "    return sqlTrainLob, sqlTrainLabel\n",
    "\n",
    "def get_SQLtest1(index, conn):\n",
    "\n",
    "    queryLob1 = f'''SELECT * FROM \"NoAuction_DecPre\" \n",
    "                  WHERE \"RandID\" = {index}\n",
    "                  AND istrainingdata = 0\n",
    "                  limit 200;'''\n",
    "    ResLob1 = pd.read_sql(queryLob1, conn)\n",
    "    sqlTestLob = ResLob1.loc[:, 'pa1':'vb10']\n",
    "    \n",
    "    queryLabel1 = f'''SELECT * FROM \"NoAuction_DecPre_Label\" \n",
    "                    WHERE \"RandID\" = {index}\n",
    "                    AND istrainingdata = 0\n",
    "                    limit 200;'''\n",
    "    ResLabel1 = pd.read_sql(queryLabel1, conn)\n",
    "    sqlTestLabel = ResLabel1.loc[:, 'direction']\n",
    "    sqlTestLabel = sqlTestLabel*(-1) + 2 - 1\n",
    "    \n",
    "    return sqlTestLob, sqlTestLabel\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    \n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX.reshape(dataX.shape + (1,)), dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to postgresql on VM\n",
    "engine = create_engine('postgresql://yijing:1qaz2wsx@155.246.104.52/hftlob')\n",
    "#conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 40)\n",
      "(101, 100, 40)\n",
      "(101, 100, 40)\n",
      "Train on 101 samples, validate on 101 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 1.0985 - accuracy: 0.3564 - val_loss: 1.0979 - val_accuracy: 0.8515\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.0979 - accuracy: 0.7228 - val_loss: 1.0966 - val_accuracy: 0.8515\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1.0969 - accuracy: 0.7228 - val_loss: 1.0951 - val_accuracy: 0.8515\n",
      "Epoch 4/200\n",
      " - 1s - loss: 1.0957 - accuracy: 0.7228 - val_loss: 1.0933 - val_accuracy: 0.8515\n",
      "Epoch 5/200\n",
      " - 1s - loss: 1.0944 - accuracy: 0.7228 - val_loss: 1.0912 - val_accuracy: 0.8515\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-483ae707003d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtestY_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdeeplob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare training data. We feed past 100 observations into our algorithms and choose the prediction horizon.\n",
    "with engine.connect() as conn:\n",
    "    for i in range(100):\n",
    "        sqlTrainLOB, sqlTrainLabel = get_SQLtrain1(i, conn)\n",
    "        sqlTestLOB, sqlTestLabel = get_SQLtest1(i, conn)\n",
    "        trainX_CNN, trainY_CNN = data_classification(sqlTrainLOB, sqlTrainLabel, T=100)\n",
    "        trainY_CNN = np_utils.to_categorical(trainY_CNN, 3)\n",
    "        \n",
    "        testX_CNN, testY_CNN = data_classification(sqlTestLOB, sqlTestLabel, T=100)\n",
    "        testY_CNN = np_utils.to_categorical(testY_CNN, 3)\n",
    "        \n",
    "        deeplob.fit(trainX_CNN, trainY_CNN, epochs=200, batch_size=64, verbose=2, validation_data=(testX_CNN, testY_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model Training\n",
    "deeplob.fit(trainX_CNN, trainY_CNN, epochs=100, batch_size=32, verbose=2, validation_data=(testX_CNN, testY_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "with engine.connect() as conn:\n",
    "    sqlTestLOB, sqlTestLabel = get_SQLtest1(1, conn)\n",
    "    testX_CNN, testY_CNN = data_classification(sqlTestLOB, sqlTestLabel, T=100)\n",
    "    testY_CNN = np_utils.to_categorical(testY_CNN, 3)\n",
    "    \n",
    "    for i in range(10):\n",
    "        sqlTrainLOB, sqlTrainLabel = get_SQLtrain1(i, conn)\n",
    "        trainX_CNN, trainY_CNN = data_classification(sqlTrainLOB, sqlTrainLabel, T=100)\n",
    "        trainY_CNN = np_utils.to_categorical(trainY_CNN, 3)\n",
    "        \n",
    "        deeplob.fit(trainX_CNN, trainY_CNN, epochs=5, batch_size=32, verbose=2, validation_data=(testX_CNN, testY_CNN))\n",
    "\n",
    "        deeplob.evaluate(testX_CNN, testY_CNN, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
